
Kubernetes Package Administration with Helm

Course Overview
Course Overview
Hi everyone. My name's Andrew Pruski, and welcome to my Pluralsight course, Kubernetes Package Administration with Helm. Helm is a package manager for Kubernetes. With Helm, applications are bundled into charts, which makes it easy to build, install, upgrade, and share complex Kubernetes applications. Some of the topics that we'll cover in this course are how to configure our local environment to work with Helm, installing Helm, and adding Helm repositories so that we can deploy charts to a Kubernetes cluster. Then we'll explore Helm releases, how to deploy a chart to Kubernetes, and then retrieve information about that deployment, or as it's known with Helm, a release. We'll look at how we can easily upgrade an application using Helm, and then just as easily roll that upgrade back. We'll also dive into charts themselves and have a look at the internals before we go ahead and create our own custom chart. Then we'll package up that chart so we can deploy it to either a Helm repository running locally or a remote repository. All the topics that we will cover will be accompanied with demos so that you will have all the code needed to get working with Helm. By the end of this course, you'll be able to work with Helm charts and explore the possibilities that it can offer you and how it can simplify working with applications in Kubernetes. Before getting started with this course, I recommend that you have an understanding of Kubernetes, its architecture, and how to deploy applications to it. I hope that you'll join me to learn how to manage Kubernetes packages with Helm to simplify working with applications in Kubernetes.

Installing and Configuring Helm
Introduction
Hello, and welcome to this course, Kubernetes Package Administration with Helm. My name's Andrew Pruski. I'm a Microsoft Data Platform MVP and Certified Kubernetes Administrator originally from Whales, but I'm now based in Ireland, and I'll be taking you through this course. This module is all about installing and configuring Helm. In this module, we'll get an overview of Helm, what it is, its history, some usage statistics, and the differences between Helm version 2 and version 3. We'll then look at setting up our own local environment, the tools that we'll need, and then how to install Helm itself. Once we've covered that, we'll then look at configuring Helm and go over some Helm commands. Then finally, we'll look at the stable repository, which is managed on the Kubernetes charts GitHub repository.

Helm Overview
But first, what is Helm? Helm is a package manager for Kubernetes. These packages are called charts, and in these charts we define the applications that we want to deploy to Kubernetes in YAML files. So we take all the YAML files that we've deployed to Kubernetes, our deployment.yaml, service.yaml, etc., and bundle them up into one easy‑to‑manage package. We then deploy that package or chart to our cluster. With Helm, we can deploy complex applications to Kubernetes in one easy‑to‑manage chart. We can then update that chart and upgrade our application or easily roll back to a previous version. Charts can be stored in repositories, making them available to other members of our team so that we can guarantee the same version of the application is being deployed and worked on throughout our organization. Let's go through the history of Helm. Helm was created in 2015 Deis, which has now being acquired by Microsoft. Helm was introduced at KubeCon in November 2015. That version, now known as Helm Classic, was merged with Google's Deployment Manager in January 2016 into what is now the main Helm project on GitHub. It has over 30,000 GitHub stars and has more than 2 million downloads per month. Finally, it graduated from the Cloud Native Computing Foundation in April 2020, joining the ranks of such projects like Kubernetes itself, Prometheus, CoreDNS, and containerd. I mentioned that the Helm repository on GitHub has 30,000 GitHub stars and more than 2 million downloads per month, so here's a few more stats on Helm usage to show how broadly it has been adopted. With over 13,000 contributors, 9400 code commits, 14.5 thousand pull requests, 128,000 contributions, and 1.6000 contributing companies, the two top companies being Microsoft and codecentric AG, Helm is very much actively worked on and widely used out in the Kubernetes ecosystem. One of the biggest changes made to Helm recently has been the release of Helm version 3. But what are the differences between Helm version 3 and Helm version 2? Tiller has been removed from Helm version 3. In Helm version 2, we would have had to run helm init to install Tiller on the Kubernetes cluster we were working with. But that now is no longer needed. The helm search command now supports local repository searchers and making search queries against the Helm Hub. Various other commands have also been updated or removed completely. Along with helm init, which is no longer required, helm reset and serve have also been removed. Another key change is that a release name is now required with helm install, or we need to specify the generate‑name flag to generate a random name for our release. Releases are now scoped to namespace, whereas in Helm version 2, releases were stored in the same namespace as Tiller. This meant that once the name was used for a release, it could not be reused. V3 removes that issue. The Chart API version has been changed to v2, and the Chart Dependency Management System has also been updated. Requirements.yaml and requirements.lock have been moved to chart.yaml and chart.lock. The new format is recommended, but Helm version 3 is compatible with Chart API version 1. There are other changes made in Helm version 3, which I won't go over here, but I do recommend you check out the full breakdown of the changes on the Helm website. But I do want to talk about what I think is the main change in Helm version 3, the removal of Tiller. Tiller was the server‑side component of Helm to deploy objects to a Kubernetes cluster. This meant that Tiller could have extensive privileges within the cluster I call security issues if Helm had not been deployed correctly. With Tiller removed, security for Helm is much simpler. Helm version 3 permissions are evaluated from our local kubeconfig file. As Helm version 3 is the newest version, this course will focus solely on Helm version 3. Before we move on to setting up our local environment, I want to quickly talk about charts. I've mentioned it a few times in this course, but what exactly are charts? When we deploy an application to Kubernetes, we may have multiple YAML files contain our deployment where we define our application to run in a container, a service to expose our application, and a secret to hold any sensitive information. Without Helm, we would deploy each of these YAML files to Kubernetes with kubectl apply one at a time. This is fine for simple deployments with only a few YAML files, but what about more complex deployments? How would we manage deploying large amounts of YAML files? Deploying them individually would be time consuming and prone to human error. It could be very easy to miss one YAML file, resulting in a failed deployment. Helm wraps up all of our YAML files into one easy‑to‑deploy and maintained object. We can deploy them with one command, helm install. Wrapping up all the YAML files into one chart also allows for version. We can create different versions of the charts as we change the YAML files within them, making it easy to track changes to our application. This also makes upgrading and rolling back deployments really simple, and we will cover that in this course.

Setting up Your Environment
Okay, let's go ahead and run through how to set up our local environment. For the demos in this course, I'll be running on Windows 10. This isn't a requirement to follow along. All the tools I'll be using are cross platform and free, it's just the OS I'll be using. The tools I'll be using are Visual Studio Code, a great coding development environment with extensions for Kubernetes, which includes Helm. This will provide a graphical view of any repositories I have installed, and it will allow me to view any Kubernetes objects deployed via a chart through an easy‑to‑use GUI. Docker, this will be our container runtime for our local Kubernetes cluster. I'll also be using Docker with a Windows subsystem for Linux 2 integration feature. This became generally available in Windows 10 version 2004 and removes the need for Docker to spin up a VM in Hyper‑V to allow Linux containers to run on Windows. And then I'll be using the Kubernetes feature in Docker Desktop. There are other options for running Kubernetes locally, Minikube, MicroK8s, and K3s if you're on a Mac or Linux distribution, but as I'm on Windows and already using Docker, I'll use a built‑in Kubernetes feature as it's, in my opinion, the easiest way to get a local Kubernetes cluster up and running. It's literally just a matter of checking a tick box to get a one‑node cluster up and running on your local machine. So let's go ahead and get Helm installed.

Installing Helm
Now that we have our local environment set up, we can install Helm. There are a few ways that we can install Helm, and the one used is generally determined by the OS that we are working on. We can grab the binary releases by manually downloading them, unpacking them, and then moving the binary to a location in our path environment variable. Helm has an installer script that we can run automatically to grab the latest version and install it, and it's also available through snap. The Snapcrafters community maintains a snap version. And then we can also use package managers. It's available via Homebrew for macOS, out for Debian and Ubuntu distributions, and via a Chocolatey package for Windows. So I'll be using Chocolatey as I'm on Windows 10.

Demo: Installing Helm
Let's dive into a demo and get Helm configured on our local machine. We'll set up our environment to use a local Kubernetes cluster installed via Docker Desktop, and then get Helm installed. Hello, and welcome to this demo in which I'm going to go over how I set up my local environment, and then I'm going to install Helm. I'm not going to go through installing each of the prerequisites as they are Windows‑specific, but if you are running on Windows, I've included links to guides to help you through installing each one of the prerequisites I mention here. The first thing I did was install the Windows subsystem for Linux as I want to use this with my Docker Desktop install. I manually installed Ubuntu 2004 from the Windows Store, and I can see it in the output of wsl ‑‑list along with a couple of distributions added by Docker itself. Once I had the Windows subsystem for Linux installed, I then went to the Docker website to grab the MSI and ran through the Docker installation. I can confirm that I've got Docker installed here with docker version, I have my client version of Windows, and my server version, Linux. I can confirm that I have the Windows subsystem for Linux 2 based engine enabled, and then I went ahead and enabled Kubernetes so that I can get a one‑node cluster running on my local machine. I can see in the settings that Kubernetes is up and running, so I can confirm my current context, which is my Docker Desktop cluster, and then I can check my connection to my cluster with kubectl get nodes, and there you can see I have one node, my local machine. Okay, now we are good to go and install Helm. The way you install Helm does depend on the OS that you're using. As I'm using Windows, I'm going to install via Chocolatey, and there's a link to how you can install Chocolatey on your local machine there. So, I'm going to say choco install kubernetes‑helm and let the script run. And then we can see Chocolatey installing Helm on my local machine. Now that we have Helm installed, let's also install the Kubernetes extension for Visual Studio Code. This is really handy as it gives us a nice GUI to browse Helm repositories So search for Kubernetes, it's the top one there developed by Microsoft. This will also install the YAML extension developed by Red Hat, as it's a prerequisite for the Kubernetes extension. Okay, that's all installed, and now we can see we have a Kubernetes logo on the left‑hand side of Visual Studio Code. If we open up the extension, we'll see that we have sections for Clusters, Helm Repos, and Cloud Providers. And there you can see I have my local Docker Desktop cluster and I don't have any Helm repos added yet. One final note about the Kubernetes extension is that it needs various command line tools such as kubectl, Docker, Helm, and Draft. If you can't find those tools, it will offer to install them for us. However, the version of Helm that it installed is version 2. And anyway, we already have version 3 installed on our local machine. So let's draw up a path to the version 3 helm.exe file in Visual Studio Code settings. Excellent! And now the final thing we can do is run helm version and confirm the version that we're running. And there we are running version 3.2.4. We are good to go and start adding some repositories to our local Helm install.

Configuring Helm
How that Helm is installed, let's have a look at configuring it by adding a repository. But first, let's run over some of the commands we'll be using in this course. One of the first commands we would run would be helm version to check which version we have installed. With Helm version 2 we would get a client and server version as Tiller would be installed with Helm in it. With Helm version 3, we only get a client version as Tiller has been removed. Helm repo add, this would add a chart repository. We need to add repositories so that we can search for charts within them and then deploy those charts to Kubernetes. Once a repository is added, we can then search it for a chart that we wish to deploy using the command helm search repo. We can also use the versions option to view the different versions of a chart within a repository. Once we have found the chart that we wish to deploy, we can install it with the command helm install. This will deploy all the Kubernetes objects defined in the chart to the Kubernetes cluster that our kubeconfig file is currently pointed at. We can also use the dry run option to test the deployment of our chart to make sure that it will deploy successfully. With Helm, an instance of our chart running in a Kubernetes cluster is called a release, and we can check the status of our releases with the helm list command. To upgrade or roll back a release, we can use the helm upgrade or helm rollback commands. And we can view the history of a release with the helm history command. When we come on to creating our own charts, we can use the helm create command to create a new chart with default YAML files and then use the helm package command to create a chart archive from a chart directory, which can then be pushed to a Helm repository. All of these commands will be used in the upcoming demos in this course, so we'll see them in action. But first things first, let's add a repository to our local install of Helm. In order to search for charts that we can deploy to our Kubernetes cluster, we need to add at least one Helm repository to our local install of Helm. The best place to start is the stable repository, which is the official Helm repository and contains a vast array of different charts that we can use. The stable repository can also be viewed on the Helm Hub. Think of the Docker Hub, but for Helm charts. We can go to hub.helm.sh and search not only the stable repository, but many others as well. At the time this course was created, there were over 1300 charts available on the Helm Hub. But back to our local install. The stable Helm repository used to be installed by default in Helm version 2, but now in Helm version 3, we have to install it manually. We can do this with the helm repo add command. So we say helm repo add https kubernetes‑charts.storage.googleapis.com. Once that's installed, we are good to go to search for a chart and deploy it to our Kubernetes cluster.

Demo: Configuring Helm
Let's dive back into a demo and get the stable repository added to our local Helm installation. Helm version 2 used to come with a stable repository already added, but that's not the case in Helm version 3. We need to add it manually. We can confirm that we don't have any repositories ready for us to search with helm repo list, and there we are, we get an error saying no repositories to show. So let's go ahead and add the stable repository with helm repo add stable, and then the path to the stable repository. And we can see there that stable has now been added to our repositories. So now let's run helm repo list again, and there we can see the stable repository. We can also have a look at the Helm section of the Kubernetes extension for Visual Studio Code, and there we can see all the charts available in the stable repository. So now we can search the stable repository with helm search repo, the name of the repository, stable, and the name of a chart we want to search for. In this case, I'm searching for the mysql chart. And there in the output are two different charts for mysql and mysqldump, and we are good to go ahead and deploy one of those to our Kubernetes cluster.

Exploring Helm Releases
Introduction
Hello, and welcome to this module, Exploring Helm Releases. In this module, we'll deploy a chart to Kubernetes from the stable repository, and then retrieve information about that deployment. We don't use the term deployments with helm though, we used the term releases, an instance of a chart running in a Kubernetes cluster. Once we have our initial release up and running. we'll look at upgrading it and then rolling it back as well. Finally, we'll go over the components of a chart, i.e., what the function of each file within a chart is and the format of the YAML files within.

Deploying a Chart to Kubernetes
Now let's look at deploying a chart to Kubernetes. The first thing we need to do is search a repository for a chart that we want to deploy. We added the stable repository in the previous module, so we have that available for us to search. In order to search a repository, we use the command helm search repo, then the repo name, a forward slash, and then the chart name that we wish to search for. In the example on the slide, I've searched for any MySQL charts within the stable repository. The output gives us the name of the charts within the repository, the chart version and app version, which are specified in the charts.yaml file, and a description of the chart. Now that we've identified a chart and stable repository, we can go ahead and install it into our Kubernetes cluster. We run the command helm install followed by a name for our release and then the repository name, a forward slash, and then the chart name. Note that we haven't specified a version here, so the version deployed will be the latest version of the chart within the repository. If all goes well, the output will show the time the chart was deployed, the namespace it was deployed to, the revision number, which links to the chart deployment history, and some notes on deploying the chart.

Demo: Deploying a Chart to Kubernetes
Let's go ahead and deploy a chart to our local Kubernetes cluster. Hello, and welcome to this demo, Deploying a Chart to Kubernetes. I'm here on my local machine, and I can confirm that I'm connected to my one node Kubernetes cluster running on Docker Desktop. There we are, that's my current context, and I can confirm connection to the cluster with kubectl get nodes, and there is the one node of my local Kubernetes cluster. Let's list the local Helm repository we have with helm repo list, and there we have the stable repository that we added in the previous module. So let's go ahead and search the stable repository for a chart. Here I'm searching for the stable/mysql chart, and in the output I have two charts, mysql and mysqldump. I want to deploy the mysql chart to my local Kubernetes cluster, but before I do I want to get some more information about that chart. So I can say helm show chart stable/mysql, and that will show me the chart definition with things like the app version, a description, a link to the MySQL home page, and who the maintainers are. I can also have a look at the chart's REAME file with helm show read me. That's a lot of information there, so instead of looking at in the terminal, I'd like to pipe that to a file on my local machine. So I'm piping that to C:\Temp\README.txt, and then we can open it up and have a look at all the information included in our chart's README file. So we have information on prerequisites for the chart, how to install the chart, the default values for the chart, and how to delete the chart as well. If I want to pull out the values of the chart, I can say helm show values and pipe that to a values.txt file. So pipe that to the file. Back here in C:\Temp, opening up the file, and here we can see all the default values that are set for our chart. We can see the image, the image tag, and things like the mysqlRootPassword. Okay, let's go back to our code and let's do a test deployment of the chart with helm install mysql, our release name, stable/mysql, repository name and chart name, and then dry‑run ‑‑debug. This simulates an install of a release to our local Kubernetes cluster. It's a good way to test whether a chart will install to your cluster, but be aware, things can go wrong with helm install that weren't picked up in the dry run; however, all looks good here, so let's go ahead and deploy this chart to our local Kubernetes cluster. So we say helm install mysql, our release name, stable/mysql. That's executed, and there on the screen there we have the output of the notes.txt file of the chart. So let's confirm the status for release with helm list. There we can see our release mysql has been deployed to the default namespace with a revision of 1, a status of deployed, you can see the chart name, and the app version.

Retrieving Information on Helm Releases
Now that we've deployed a chart to our Kubernetes cluster, let's see what information we can get about that release. Once a chart's been deployed to Kubernetes and is now referred to as a release, an instance of a chart running in a cluster, we can view the state of that release by running helm list. From here we can see that the release, mysql, has been deployed to the default namespace. By default, helm list only lists releases that are deployed or failed. But we can add the all flag to the command to see releases in other states. For example, if a release has been uninstalled with a keep‑history flag, that release will not show up by default. We would need to use the all flag or the uninstall flag to view it. As mentioned earlier in the course, helm list only shows releases in the current namespace. The all‑namespaces flag will show all releases across all namespaces. We can also use the helm status command to view the status of an individual release, and we will see that in the demos. There are also various other helm commands that we can use to get information on our release, and we'll see those in the upcoming demo. But to view the status of the objects deployed into the cluster, we can use kubectl control commands. Kubectl get all will show the status of the pods, services, deployments, and replicasets of this release. We can see here that we have one pod running, one service with a type of ClusterIP, and a deployment with one replicaset.

Demo: Retrieving Information on Helm Releases
Let's jump back into a demo to view the information on our helm release. I'm on my local machine here, and I can view the status of all the releases on my local machine with helm list. And here as you can see I have one release with the name of mysql. I can view the status of that release with helm status mysql, and we get a whole bunch of output here. The one on the screen is from the NOTES.txt file, and I can see information about when it was deployed, the namespace it was deployed to, and the revision number. It's basically the same information as helm list, but we get information from the NOTES.txt file from the chart. If I want to get information about the manifest in the release, I can run helm get manifest, my release name, and then pipe that information to a file on my local machine. So I'm go to open up that file and have a look at what's in it. And here we have information about all the Kubernetes objects that were created by combining the templates in the chart with the default values of the chart. So I can see things here like deployment, the services created, and any other objects. Here I can also see the containers created by the release and the image that the containers were created from. If I want to get information about any custom values supplied when we deployed the release, I can run helm get values, pipe that in again to a local file, open it up. But as I haven't supplied any user values, this file will be empty. The NOTES.txt file is really handy when it comes to looking for more information about a chart, and we can grab that with helm get notes, piping that again to a file on my local machine, open it up, and we can have a look at the notes that are supplied with this chart. And this gives us a whole bunch of information on how to connect to MySQL running in it and how to install MySQL client and how to connect to the database from outside the Kubernetes cluster. So far, we've picked bits and bobs from the chart. Before we get everything that we can from the release, we can say helm get all and then our release name. Again, piping that to a file on local machine, open that up, and we can see things like the status of the release, our manifests, and we'll have the contents of the NOTES.txt file at the bottom as well. But let's close that down and have a look at the Kubernetes objects that are running in our cluster. We can do this with kubectl get all, execute that, and we can see we have one pod running with a service with the type of CLUSTER‑IP, the deployment, and then the replicaset of that deployment. Okay, let's clear that. And let's have a look at the history release with helm history and then our release name, Hit Execute, and we can see we have a history of our release. So we've only got one revision with a status of deployed. We see the CHART, our APP VERSION, and a DESCRIPTION. Clearing that, now let's go ahead and let's uninstall our release. So helm uninstall our release name, and I'm using the keep‑history flag. Now if we run helm list, we won't see the release in the output. However, if we go ahead and say helm list all, we'll be able to see information about our uninstalled release. Helm list by default will not show any uninstalled releases. Finally, to clean up. I'm going to say helm delete mysql. It says it's uninstalled. But as we've already uninstalled it, what's it's really done is just delete the history of the release.

Upgrading a Release
Now we've deployed a Helm chart into a Kubernetes cluster, let's look at deploying a specific version of a chart and then upgrading it. Earlier when we searched for a chart, we didn't use the ‑‑versions flag, so the output of helm search repo showed us the latest version of the chart available in the repository. If you want to see all the specific versions of a chart available, we can use the ‑‑versions flag to see which are in the repository. To install a specific version of the chart, we run the helm install command as before. We say helm install, specify a name for the release, in this case, mysql, then the repository name and chart name, and this time, we use the ‑‑version flag and specify the version we wish to deploy to the Kubernetes cluster. In this case, we'll deploy chart version 1.6.3. Once deployed, we can use the helm list or helm status commands to verify the status of the release and use the kubectl commands to check out the status of the Kubernetes objects deployed. Now that we have a specific version of our chart running in our cluster, let's look at upgrading it. To upgrade a Helm release, we use the helm upgrade command. For this upgrade, we are upgrading the chart from version 1.6.3 to 1.6.4. So we say helm upgrade, the release name, in this case, mysql, then specify the repository name, the chart name, and the newer version that we wish to deploy into the cluster. Once that command is executed, the objects deployed will be upgraded as needed. For instance, if there is an image version change, the existing pods will be terminated and new ones created according to the roll‑out strategy specified in our deployment YAML file. If we specify to recreate strategy, all pods will be terminated before new pods are created. And if, and this is the more common usage, we used a roll‑out strategy of rolling update, the pods will be terminated and spun up according to the maxSurge and maxUnavailable values within the YAML file. Once the helm upgrade command has been run, we can use the helm list command to view the status of the release. We can see that now we have a value of 2 for our release revision, the initial deployment, and then the upgrade. To see information on the revisions, we can run the helm history command, then our release name, mysql, the state that shows the initial release, and then the upgrade that superseded it. The description field also gives us more detailed information, and we can see the app version in each revision.

Demo: Upgrading a Release
So let's run through deploying a specific version of a chart and then upgrading it. Hello, and welcome to this demo, upgrading a helm release. What we're going to do here is search the stable repository for a mysql chart, same as was in the previous demos. And here, we can see as before we have two charts returned, mysql and mysqldump. Now, as we didn't specify the versions flag, the charts returned will always be the latest versions of those charts, so let's go ahead and use the versions flag to have a look at all the different versions of the mysql chart available in the stable repository. So saying, helm search repo stable/mysql, this time with a versions flag, and here we get all the different versions of the mysql chart in the stable repository. Now the one I'm going to go for is version 1.6.3, so let's deploy that to our local kubernetes cluster. So I'm saying helm install release name/mysql, the repository named stable/chart name mysql, and here, I specify the version I want to deploy 1.6.3. Let's deploy that and we should see the output of the notes.txt file as before where we ran helm install. Lets clear that out and let's confirm it's deployed with helm list, and there we can see our release, mysql has a status of deployed, the chart is mysql‑1.6.3 with an app version of 5.7.28. Okay, let's have a look at the kubernetes objects deployed as well with kubectl get all and we can see that we have a pod, a service, deployment, and one replica set. Let's now go ahead and let's upgrade that deployment. So we say helm upgrade our release name mysql with the repository name of the chart that we upgrade to, the chart itself, and then the version of the chart. And here, I'm going with version 1.6.4, 1 up from the previous version. So let's run the upgrade and we'll get the usual output from the notes.txt file, turn some information about the chart, but if we scroll up, we'll be able to see that our chart has been successfully upgraded and now has a value of 2 for its revision. So let's clear that out and we'll have a look at the output of helm list. Here we can see our release mysql, revision status of 2, our chart version is now mysql‑1.6.4, an app version of 5.7.30. We have successfully upgraded our mysql release. Let's go ahead and have a look at the history release with helm history. We can see now we have two entries, the first one the initial install and then our upgrade to the later version. Finally, let's have a look at the kubernetes objects deployed with kubectl get all. As before, we have one pod, one service, our deployment, but now we have two replica sets, the old replica set for the initial install and a new replica set running the upgraded version of mysql.

Rolling Back a Release
Now that we deployed a chart to Kubernetes and upgraded it, let's have a look at how we can roll back that release if we need to. Here, we have the history of the release, the initial deployment, and then the upgrade. So let's see how we can roll that back. We can see that each step in the output has a revision number, so we use that to roll back the release. To roll back a release, we use the helm rollback command. In this case, we are going to roll back the release to revision 1, the initial deployment. So we say helm rollback, the name of the release, mysql in this case, and then we specify the revision that we want to roll back to. Once that's executed, we can then run the helm list command again or helm status and see the revision has moved on to revision 3. We haven't gone back to 1 that we specified, the revision number always increases. As with the upgrade, the pods associated with the release will be terminated and new ones spun up according to the rollout strategy that we specified in the deployment YAML file. If we specified recreate, all pods will be terminated before a new one is created, and if we specified rolling update, pods will be terminated and new ones spun up according to the value specified in the deployment YAML file. Once the rollback command has been executed, we run helm history to see the rollback has taken place. So for this release, we can see the initial deployment, the upgrade, and then the rollback, which is marked as revision 3.

Demo: Rolling Back a Release
Let's go ahead and roll back the release that we upgraded in the previous demo. Let's run helm list and have a look at the releases on our local machine. This is following on from the previous demo where we deployed a MySQL chart and upgraded it to version 1.6.4. Let's now look at rolling that back to the version initially deployed. So let's have a look at the history of our release with helm history, and our release name, mysql. We can see here we have two rows returned, the initial install, and then the upgrade that we performed. Let's also have a look at the Kubernetes objects deployed in our cluster. We have one pod running MySQL, a service, and we have two ReplicaSets, the initial ReplicaSet that was deployed with the initial install of our chart, and then the new ReplicaSet that was created when we upgraded our release. Let's have a look at those ReplicaSets. So you run on kubectl get replicasets, and here are the two for our deployment. What we'll see when we run our rollback is that the pods will move from the newest ReplicaSet back into the older ReplicaSet, which contains the older version of the application. So let's go ahead and roll back our release. We say helm rollback mysql, and then the revision that we want to roll back to, which in this case, will be 1, the initial deployment. Execute that, and we can see that our rollback was a success. So let's have a look at the history of our release now, and we can see we have three revisions for our release, the initial deployment, the upgrade, and now our rollback. The history always increments by one. So even though we've rolled back to revision 1, we now see that as revision 3. So let's have a look at the Kubernetes objects in the cluster again. We have the same as before, one pod running MySQL, a service, the deployment, and now we can see that we've moved back to the initial ReplicaSet. Looking at the ReplicaSets with kubectrl get replicasets, we can see that we have a pod running in the older ReplicaSet now, which contains the older version of our application. We have successfully rolled back our release. One cool thing about Helm is that it stores the release history as secrets within the cluster. So even if that old ReplicaSet had been deleted, as long as we have that secret there, we'd be able to roll back our release.

Exploring a Chart
Now that we've deployed a chart, let's have a look at pulling a chart down locally and exploring the files within. In order to pull down a package chart from a remote repository and extract it, we run the command helm pull with the repository name and chart name with the untar flag. This will pull the chart down from the specified repository and a packet for us so that we can have a look at the files within. Let's go over an example chart and the files it contains. In this example, we have a chart called ourchart. Within the chart is a chart.yaml file, which is required in every chart and contains information about the charts, such as the name of the chart, the version, and a description of the chart. Then there's a values.yaml file, which contains the default configuration values for the chart, which can be referenced in the YAML files within the templates directory. And then we have a charts directory, which is a directory that contains any charts that our chart may depend on. And finally, we have the templates directory, which contains template files that when Helm evaluates a chart will send all of the files through a template rendering engine to produce manifest files, which are YAML‑formatted resource descriptions that Kubernetes can understand. Let's have a look within the templates directory. Here we have YAML files that will create Kubernetes objects when deployed. In this example, we have a deployment.yaml file and a service.yaml file that when this chart is deployed to a cluster will create a deployment and a service. Then we have the helpers.tpl file. Files in the template directory are treated as if they contain Kubernetes manifests except for any files whose name begins with an underscore. Those files are assumed not to contain a manifest, and so are not updated to be Kubernetes object definitions when the chart is deployed, but are made available for other templates to use. Those files are used to store helpers, and the helpers.tpl file is the default location. For example, we could define a function to generate labels for a Kubernetes object, place that function in the helpers.tpl file, and reference it from a YAML file in the templates directory. Finally, we have the NOTES.txt file, which is a text file that contains information about the chart, says what its default values will be, and a guide on how to deploy the chart. This information is shown in the output of helm install. But why are the YAML files stored in the templates folder called templates? Take the example here. It is a simple YAML file that will create deployment in Kubernetes. Note that we don't have any values for the deployment name, selector, label, container name, image or container port. We have these values in brackets instead, which are known as template directives. This is what makes the YAML file a template. Templates, when combined with values, generate Kubernetes manifest files when the chart is deployed. These values can be referenced from the default objects from Helm, such as the release, which is referenced here with Release.Name, or the values that are defined in our values.yaml file, which here are containerName, containerImage, and containerPort, or set using the set option with helm install. This allows for greater flexibility when deploying charts. We can change values on runtime based on, say, the environment we're deploying the chart into. So let's run through the files contained within a chart. Let's go ahead and look at creating our own chart, packaging it, and pushing it to a Helm repository in the next module, Exploring Helm Repositories

Configuring Helm Repositories
Introduction
Hello, and welcome to this module, Configuring Helm Repositories. In the previous module, we looked at searching for a chart in a repository, and then deploying that chart to a Kubernetes cluster. In this module, we are going to have a deeper look at chart repositories, starting with the Helm Hub. Then we're going to have a look at creating our own Helm chart and packaging it so that it can be deployed to a repository. Once we've packaged our chart, we will look at deploying to a local Helm repository, running it on our machine, and then we'll look at deploying our chart to a remote Helm repository.

Repository Overview
Let's have a look at what a chart repository is. A chart repository is a HTTP server that contains an index.yml file and some package charts. It can be any HTTP server that can serve YAML or TAR files and can answer get requests, which means that we have a lot of options when it comes to hosting our own chart repository and we'll look at that later in this module. As there are thousands of chart repositories out there, it would be great if there is a central location to search them all. Enter the Helm hub. Think of the Docker hub, but for Helm charts, it's available for us to browse online at hub.helm.sh and host multiple chart repositories, including the stable repository that we searched for and deployed a chart from earlier in this course. We could even add our own repositories if we want to make our charts available for widely use. It's the first place we should check when we are looking for what Helm charts are available out there. But let's move on and look at packaging a Helm chart.

Packaging a Helm Chart
Let's go ahead and look at packaging our own Helm chart. First, we need to create a chart, and we do that with the helm create command, and then we specify a chart name. I'm going to call this chart ourchart. This will create a directory with our chart name and the default files within it, a Chart.yaml file and a values.yaml file and the charts and templates directories. There is also a .helmignore file, which is used to specify files that we don't want to include in our Helm chart. Let's have a look at the default files that are created within the templates directory. We have a test directory that defines tests that can be run in order to validate that our chart works as expected when it is deployed. We're not going to define any test for this chart, so we'll remove it. Also created is the helpers.tpl file. We won't be using any custom helpers in this chart, so we could remove it, but there's no harm in leaving it there. We then have a whole bunch of YAML files that when combined with values will create Kubernetes manifest files, a deployment, a horizontal scalar, an ingress, a service, and a service account. Then finally, we have a NOTES.txt file. What we're going to do here is remove all the YAML files and replace them with our own files to generate a simple service and deployment when our chart is deployed. Let's start with the deployment.yaml file. These easiest way to do this is with kubectl. Note that I'm using kubectl version 1.18 with just some minor syntax changes compared to previous versions. Let's go ahead and create a deployment.yaml file that will create us a custom deployment running one nginx pod. So we say kubectl create deployment, and then give our deployment a name, in this case, nginx. Then we specify a container image we want to build from. So ‑‑image=nginx. Then we say ‑‑dry‑run=client so that we won't deploy anything to our Kubernetes cluster. This command used to be just dry‑run without the client part in previous versions of kubectl, so watch out for that. But moving on, we then specify an output format. In this case, yaml. When we run this command, we'll get the deployment.yaml in the output, which we can copy and paste into our deployment.yaml file or redirect the output straight to a file. Now let's create a service with kubectl so that we can connect to our nginx pod created in our deployment. Run the command kubectl expose deployment nginx. Then we specify the type of service we want to create. Here I'm the creating the service with a type of load balancer so that we'll get an external IP address for our service if created in a cluster that supports load balancers, such as Amazon's Elastic Kubernetes Service. Or if we deploy to our local Docker Desktop Kubernetes cluster, we'll get an external IP address of localhost. Then we pick a port, going with port 80 here. And then we have the last two commands, the ‑‑dry‑run=client prevents anything from being run, and then we specify an output of yaml. When we execute this command, we'll get the YAML displayed on the left‑hand side of the screen here, which we can then drop into our chart template directory. Here we have the templates directory for our custom chart. We've removed all the YAML files created by default and dropped in the deployment.yaml and services.yaml file that we created with our kubectl commands. We still have the helpers.tpl file. We're not going to use it, but there's no harm in leaving it there. And finally, we have our NOTES.txt file. We can update this to provide information about our chart to the user when it is deployed. Let's go up one directory in our chart from the templates directory and a have a look at the files there. The chart.yaml file is where we define, amongst other things, the chart version and the chart API version. Along with the name of the chart, these are the only required fields in the chart.yaml file. Other optional fields that can be defined in the chart.yaml file are, for example, a list of dependencies that this chart requires, information about the maintainers of the chart, and maybe a URL to the source code of the project that produced this chart. We'll want to update the chart.yaml file in the real world, but for this example, I'm going to leave all the values within as is. Then we have our values.yaml file. If we wanted to specify any custom default values for our chart, we could drop them in here. But for now, again, we'll leave it as it is. Then we have our charts directory. Our chart doesn't depend on any other charts, so there's nothing to do there. And finally, we've already dropped our customize YAML files into the templates directory, so we are good to go and deploy our chart. To deploy our chart, we say helm install, give the release a name, in this case ourchart, and then we specify the location of our chart. If all goes well, we should see a status of deployed in the output of the command and the output of our NOTES.txt file. Here, I've simply dropped the text A test Helm Chart into that file, and we see that in the output. Now that our chart has been deployed, we can check on its status by running helm list. We'll get the name of our release returned with the namespace that it was deployed to, the revision, when it was last updated, the status of the release, and the chart and app version. All looks good so far, so let's check the deployment service that were created when we deployed the chart. Kubectl get all will show us the objects created, and here we can see that one nginx part has been created and has a status of Running. We have our service created as well with the type of LoadBalancer, and as I've deployed this to my local Docker Desktop Kubernetes cluster, it has an external IP of localhost. Then we can see the deployment created and the replica set of the deployment. Now that we know our chart can be deployed successfully, let's go ahead and package that chart so it can be pushed to a Helm repository. So we say helm package, the path to our chart, and the location of where we want the packaged chart to be created. In this case, C:\charts. If all goes well, we'll see a message saying that Helm has successfully packaged our chart and saved it to C:\charts\ourchart‑0.1.0.tgz. The version appended to the package chart name is defined in our charts.yaml file, and we can change that if we want to. Let's go ahead and run through creating a Helm chart and then packaging it in a demo

Demo: Packaging a Helm Chart
Let's go ahead and run through creating a Helm chart and then packaging it in a demo. Hello, and welcome to this demo, Packaging a Helm Chart. What we're going to do is create a simple chart with a deployment and a service and then package it so that we can push it to a Helm repository. First thing we need to do is create our own chart. So we say helm create, and then a name for our chart, ourchart. Once that's executed, we can go and have a look at the chart directory on our local machine. So we say ls .\ourchart, and there we can see that we have the charts directory, the templates directory, the helmignore file, the Chart.yaml file, and the values.yaml file. Let's have a look at the templates directory. Here we have a tests directory where we could put any tests for our chart, the _helpers.tpl file, a whole bunch of YAML files, and a NOTES.txt file. What we're going to do here is remove all the default YAML files and replace them with our own templates. So let's get rid of those. Okay, and now we can create our own deployment.yaml file with kubectl create deployment. This will create a simple deployment running one pod of nginx. I'm using a dry‑run=client, an output=yaml, so I can grab this and drop it into a YAML file and copy it into my chart. So let's run the command again and redirect the output into a YAML file that is in our chart. So exactly the same statement as before, but this time, just pipe in that output into a deployment.yaml file in the templates directory in my chart. Now what I'm going to do is actually run the kubectl create deployment statement without the dry‑run flag in order to actually create the deployment nginx on my local Kubernetes cluster. The reason I'm doing that is because I need that deployment there in order to be able to run my exposed command to get the YAML file for the service I want to drop into my chart. If the deployment nginx was not present on the cluster, this exposed command would error out. But as it's there, it will generate the YAML that we need. So Let's go ahead and let's pipe that to a service.yaml file in our charts templates directory. Okay, so we have our deployment.yaml and our service.yaml. Let's delete that deployment nginx in the cluster as we don't need it. The next thing I'm going to do is replace the NOTES.txt file with a custom file. And I'm being really simple here. All that file is going to say is "A test Helm Chart." Let's do a little bit more of a cleanup of our chart. So we're going to remove the charts directory as our chart doesn't have any dependencies and the tests directory as our chart doesn't have any tests either. Okay, now we can go ahead and deploy our chart. So we say helm install, a name for our release, ourchart, and then the path to ourchart. If all has gone well, we should see a status of deployed, Revision 1, and the output of our NOTES.txt file, A test Helm Chart. We can also confirm everything with helm list. So we run that, and we get the output, our release name, ourchart, it's the namespace default, and a status of deployed. Let's also check out the Kubernetes objects with kubectl get all. Here we can see one pod running, our service with a type of LoadBalancer. So I've got an external IP of localhost, our deployment, and the replicaset for our deployment. We've confirmed that our chart can be deployed successfully. So let's delete that release and make some updates to our chart. I can run helm list to confirm that the release has been deleted. And there we are, our release is no longer there. Now what we're going to do is update our deployment.yaml file and remove the hard‑coded name for the deployment and replace it with a template directive. Helm has various built‑in objects that are passed to templates from the template rendering engine. But what I'm using here is Release and its subobject Name. So what I'm going to do is copy this template directive and drop it into my deployment.yaml file. So, copying the value and then replacing the hard‑coded name for my deployment nginx with this template directive. What this will do when I install my chart is that the deployment will now have the name of the release instead of the hard‑coded name, nginx. Also, let's create a default value for the container image in our chart. So removing the old values.yaml file and creating a new one with one value of nginx:1.17 for the containerImage. So quickly looking at the values.yaml file, there it is, one value for containerImage, nginx:1.17. And now we can update our deployment.yaml file to use that new value. So we copy values.containerImage into the deployment.yaml in replace of the hard‑coded image, nginx. We can have multiple entries in our values.yaml file and reference them in template directives with the values object. Okay, let's redeploy our chart with helm install. Hit Execute. Okay, that's deployed. We can see our NOTES.txt file I put there. Status of deployed. Let's confirm all that with helm list. Release looks good. We can see the name of it, ourchart. And now let's have a look at the Kubernetes objects deployed, and we can see that the deployment has a name of ourchart, the release name, instead of the hard‑coded value we had before, nginx, because we've used that temporary directive. Let's have a closer look at that deployment. So I'll run kubectl get deployment with a jsonpath query to pull out the container image that is running in our deployment. And we can see here that it is nginx:1.17, the value that we dropped for the containerImage in our values.yaml file. So some final testing before we package our chart. Let's go ahead and upgrade our chart using the helm upgrade command, path to our chart, and then we're going to override the value for the containerImage in the values.yaml file with a set flag. So I've said set containerImage=nginx:1.18. Let's go ahead and run that and upgrade our release. There we go. Our release has been upgraded. And let's run the same kubectl get deployment before and have a look at the containerImage. Brilliant! We've overridden the default value, and we're now running nginx:1.18 in our release. Now that we've done all that testing and confirmed our chart works, we can now package our chart. So we're saying helm package, path to .\ourchart, and then specifying the destination, in this case, C:\Charts. And then we have the message that our chart has been successfully packaged and saved to C:\Charts\ourchart‑0.1.0, which is the default version in our Chart.yaml file. We now have our package chart ready to be pushed to a Helm repository.

Creating a Local Helm Repository
Now that we have packaged a chart, let's look at creating a local Helm repository where we can push it to. There are a few tools that we can use to save our Helm chart, but the one I want to focus on in this section is ChartMuseum. It's an open source Helm Chart Repository that we can run locally to test pushing Helm charts to. The reason I like ChartMuseum is that it's cross‑platform, there are multiple different ways we can run it, and it has support for various different cloud backend storage. But here I want to run it locally in my Docker desktop Kubernetes cluster so that I can test packaging a chart and pushing it to a repository. ChartMuseum can be run as a Helm chart. So let's go ahead and get started. Let's test deploying a chart to an instance of ChartMuseum running on our local Kubernetes cluster. To do this, we need to deploy ChartMuseum into our cluster using Helm. In order to deploy ChartMuseum locally, we run helm install, then give a name for our release, chartmuseum, and then the repository where the chart is stored. Chartmuseum is stored in the stable repository. Finally, we have to set the flag DISABLE_API to false. The ChartMuseum API is disabled by default, so we need to enable it with this flag so that we can push our chart to it. We hit execute, and we see that our chart has a status of deployed, and we get the output of the NOTES.txt file, which gives us instructions on how to access ChartMuseum. In order to be able to connect to ChartMuseum and push charts to it, we need to forward a local port to the open port on the pod running ChartMuseum. So we grab the pod name with kubectl get pods, label app=chartmuseum, and use a jsonpath query to return the pod name and set it to the variable POD_NAME. Then we run our kubectl port‑forward command. Here I am forwarding port 8080 locally to port 8080 on the chartmuseum pod. Now that we have Chart Museum up and running and we have set up port forwarding, we can go ahead and add Chart Museum as a Helm repository. So we say helm repo add, provide a name for our repository, chartmuseum, and then the address http://127.0.0.1:8080, which we are port forwarding to the pod in our Kubernetes cluster that is running ChartMuseum. Now that we have ChartMuseum running, and have added it as a repository, let's push our package chart to ChantMuseum. We do this with curl. One thing to watch out for though, when running this in PowerShell, is the version of PowerShell that you are running. Curl now ships with Windows 10, however, in PowerShell version 5.1 curl is alias to Invoke‑WebRequest, so the command on the slide will not work. We need to remove the alias in order to use curl, and I'll show you how to do this in the upcoming demo, but here I'm using PowerShell version 7, which does not alias curl to Invoke‑WebRequest. So we say curl using the flag data‑binary, the name of our chart with an @ prefixed, and then http://localhost:8080/api/charts. If the command works, we'll see saved true in the output. Once our charts have been pushed to ChartMuseum, we can then search ChartMuseum for our chart. So the first thing we need to do is update our Helm repos. When we added the ChartMuseum repository, an index.yaml file for that repository was cached locally on our machine. The index.yaml file contains information about the charts available in the repository. This was not updated automatically when we pushed our chart to ChartMuseum, so we need to run helm repo update in order to update all the cached index.yaml files on our machine. This will pick up the fact that we pushed a chart to ChartMuseum. The local copy of the index.yaml file for chartmuseum will be updated, and we'll be able to search for our chart. When the command completes, we'll get a message in our output that we have successfully gotten updates for our repositories, both the stable repository, which we added in a previous module, and chartmuseum. Watch out for this, as it seems that this message is always displayed even if there have been actually no updates to the repositories, so it's not a good measure of if there have been any changes. But anyway, in this case, we know that there's been an update to ChartMuseum, as we have pushed our chart to it. So now we can search for our chart. The command is helm search repo, and then the repository name, chartmuseum/, and then our chart name. If all has gone well, we'll see our chart in the output. We have successfully pushed a chart to a Helm repository and searched for it. Those version numbers in the output are just the default values in the chart.yaml file for a newly created chart, as is the description text. We didn't update them for this example, but in a real world situation, we would have updated our chart.yaml file to include the version numbers that were correct for our chart.

Demo: Creating a Local Helm Repository
Let's go ahead and run through a demo of spinning up ChartMuseum locally and pushing a Helm chart to it. Hello, and welcome to this demo, Creating a Local Helm Repository using ChartMuseum. Just dive straight in, and the first thing we need to do is test deploy in ChartMuseum with helm install and the ‑‑dry‑run ‑‑debug options. All looks good. We've got the output of our NOTES.txt file there. So let's go ahead and install ChartMuseum into our local Kubernetes cluster. So running helm install, removing the ‑‑dry‑run and ‑‑debug options, and here we need to override the default value in the chart using the ‑‑set flag. By default, the ChartMuseum API is disabled, so we need to enable it by setting the value of DISABLE_API in the chart to false using the ‑‑set flag. This will allow us to connect to ChartMuseum and push our chart to it. So let's run that, and there we get the output of the NOTES.txt file, which tells us how we can connect to ChartMuseum by setting up port‑forwarding. Confirming our release with helm list. All looks good. Let's have a look at the ChartMuseum pod. There it is running. Okay, so now we need to grab that ChartMuseum pod name, set it to a variable pod name, and we can drop that into our kubectl port‑forward command. That's now up and running, so I'm going to open up a new terminal, we'll leave the port‑forward running, and then grab the address, http://127.0.0.1:8080, drop it into my web browser, and there we are, I've confirmed the ChartMuseum is successfully installed and up and running. Now what I'm going to do is run helm help and have a look at the default location of where our repositories.yaml file lives that contains information about the repositories I've added to my local helm install. And we can see it there under the repository‑config string value, C:\\Users\\apruski\\AppData\\Roaming\\helm\\repositories.yaml. So I'm going to grab that location, drop it into File Explorer, and open up the repositories.yaml file. And as I've only got the stable repository added so far, that is the only value I have in this file. Now let's add ChartMuseum as a helm repository. So we say helm repo add chartmuseum, and then the HTTP path 127.0.0.1:8080. We can confirm that ChartMuseum has been added as a repository with helm repo list, and there it is, along with the stable repository. Let's go back and have a look at that repositories.yaml file, and we can see that it's been updated and we have a record for ChartMuseum in it. As ChartMuseum is now up and running, and we've added it as a repository, let's go ahead and push our package chart to it. One thing to watch out for here is that we're going to use curl to push the chart to ChartMuseum, but if you're running in PowerShell version 5.1, you'll need to remove the alias that maps curl to Invoke‑WebRequest. You can do this with Remove‑Item alias:\curl. I'm running in PowerShell version 7 here, so I don't need to do this, and I can confirm that by running curl help, which will error out if you're running in PowerShell 5.1 and still have the alias. So now let's go and push our chart to ChartMuseum using curl. So I'm saying curl ‑‑data‑binary, the name of our chart with an @ prefix, and then http://localhost:8080/api/charts. Run that, and if all's gone well, we should see saved true in our output. So now that we've pushed the chart up to ChartMuseum, let's search for our chart. So we say helm search repo chartmuseum/ourchart, but nothing's come back. Let's have a look at helm help again. When we added ChartMuseum as a repository, an index.yaml file for that repository was cached locally, and we can see its location in the ‑‑repository‑cache string in the output of helm help. So I'm going to grab that location, C:Users\\apruski\\AppData\\Local\\Temp\\helm\\repository, drop it into File Explorer, and there I can see chartmuseum‑index.yaml, and we can see that it has no entries for any charts. What's happened here is that file was cached before we pushed our chart to ChartMuseum. So we need to update it by running helm repo update. Let that execute, and we can see that we've got an update from ChartMuseum and the stable chart repository. Be warned with this, that message always seems to display even if there haven't been any updates to those repositories, so it's not a good indication if there have been any changes made. However, we know that there's a change made to ChartMuseum because we pushed our chart to it. Now let's go back and have a look at the chartmuseum‑index.yaml file. We can see that it now has indeed been updated and we have a record for ourchart. So we could go back and run helm search again and see if we get an output when we search for ourchart. And there we go. We can see that as the chartmuseum‑index.yaml file has been updated, we now get ourchart returned when we search for it in ChartMuseum. We could also have a look at our chart in ChartMuseum by looking at the helm section of the Kubernetes extension for Visual Studio Code. So do a refresher, ChartMuseum has popped up, we expand that, and there is our chart in ChartMuseum. Okay, we've pushed our packaged chart to ChartMuseum. Let's now go ahead and test deploying it from ChartMuseum, just to make sure all is well. So let's run helm install release name ourchart, repository name, chartmuseum, and then our chart name. All looks good so far. Finally, to confirm, we can run helm list and have a look at the output. And there we go. We can see that ourchart is running. So, we have successfully taken our packaged chart and pushed it to a local helm repository.

Creating a Remote Helm Repository
Now that we've created and pushed chart to a local repository, let's have a look at pushing a chart to a remote Helm repository. We have a lot of options here as a Helm repository can be any HTTP server that can serve YAML or TAR files and can answer git requests. So we have, as in the previous example, ChartMuseum or we could use cloud storage, such as Amazon S3 or Google Cloud Storage. Then there are third‑party options such as Nexus or JFrog Container Registry, but the one I want to focus on here is GitHub as we can set up a repository to host our Helm charts easily and for free. So let's go ahead and look at using a GitHub repository to host our Helm charts. On GitHub, create a new repository. Here, I've given my repository the name DemoHelmRepo. I've given it a short description, a repo for Helm charts, and I've made the repository public. Be careful here as public means anyone could have access to your charts. It's good practice to have never have anything sensitive in your charts, but in this case, it's doubly important. However, as this is a repository for a demo in which I'm going to push a very simple chart with nothing sensitive in it, I'm going to make it public. We could also initialize the repository with a read me, but in this case, I'm not going to as it's not needed. Once that's all done, we can go ahead and click Create repository to create our GitHub repository in which we are going to push our Helm chart. Now that a repository has been created, we can clone it locally. Grab the HTTPS path in the Quick setup section, and then in a PowerShell window, type git clone and then the path to the repository. Once that runs, we'll get a warning saying that we've cloned an empty repository, which is expected as we haven't pushed any charts to it yet. We now have our repository cloned locally, so let's copy our package chart into it. Once the chart has been copied in, we then run helm repo index ., this will generate the index.yml file in the current directory that contains information about our package chart, such as the name of the chart, the version, the app version, when the chart was created, and the description of the chart. The index.yml file, as we saw in the previous section, is cached locally on machines when a helm repository is added with helm repo add. This is a file that helm repo search references when we are searching for a chart so it's vital that this file be present in all helm repositories. The package chart is now in our repository and we've created our index.yml file. If we run git status, we can see both files as untracked files in our repo. We need to go ahead and stage them into our repository locally. To stage the files, we run the get add . command. This will stage all the untracked files in our current directory so we can go ahead and commit them with a git commit command and include a short message describing the changes that we've made. Finally, we can push the changes to the remote repository with git push. Once our package chart has been pushed to GitHub, we can now add our GitHub repository as a helm repository locally. We can't use the same HTTPS path we used to clone the repository down. We need to click on the index.yml file in the repo and then hit the Raw button highlighted. Then we copied the URL in our browser and it's this path we use to add our GitHub repository as a Helm repository removing the index.yml text at the end of the URL. Now that we have the URL for our GitHub repository, we can add it as a Helm repository locally. So we say helm repo add, then a name of for our repository, in this case, I've called it dbafromthecold, my Twitter handle, and then the HTTPS path that we got in the previous slide. Once we've run that, we'll see a message saying that it's been added as a repository and we can run helm repo list to confirm. Finally, to make sure that all is well, we can search our repo for our chart. So the same way we did for our local chart museum helm repository, we say helm search repo, our repo name, in this case, dbafromthecold, and then our chart name. Then we see our chart returned with the same chart, an app version, and description as before. What's happened in the background is that the index.yml file in our report has been cached locally along with a text file containing the names of any charts in our repo. This is the file that is searched by helm search repo when we want to search for our chart. It's also the reason we need to run helm repo update when we add charts to repositories as it is not automatically updated. We don't need to run the helm repo update in this case, however, as our package chart was pushed to the repository before we added the repository locally. So the cached index.yml file will already contain a reference to our chart.

Demo: Creating a Remote Helm Repository
Let's go ahead and run through a demo of setting up a remote Helm repository. What we're going to do in this demo is create a repository on GitHub, add that as a Helm repository, and then push our package chart to it. So the first thing we need to do is go to GitHub and create a new repository. So here I am on my GitHub home page. Click in the top right‑hand corner a new repository, choose a repository name, I'm going to go with DemoHelmRepo as it's available, and then a short description of what this repository is, a test repository for Helm charts. I'm going to leave this repository as public, but be aware if you do this anyone can get access to anything you push to your repository. I'm going to go ahead and click Create repository, and on the next page I'm going to get the HTTPS URL at the top there so that I can clone my repository locally. Jumping back to VS Code, and now I can use git clone and the HTTPS path and pull my repository down locally. And I've got a warning there that I've cloned an empty repository, and that's okay, we haven't pushed any charts to it. So let's navigate to that repo and copy our package chart that we packaged in a previous demo into our new repository. The next thing we need to do is run helm repo index to create an index.yaml file for our repository that has a reference to the charts within it. The index.yaml file is the file that gets cached locally when we add a repository to Helm, and it's searched when we run helm search repo. So it's vital that it exists and has a reference to all the charts within our repository. We've run our helm repo index command, so let's go ahead and have a look at the index.yaml file that was created. And we can see here that it has a reference to our chart, so we're good to go and push it up to GitHub. So let's stage all the files in our repository with git add, commit them with git commit and a short message, and then we can push them up to GitHub. Now that those files are being pushed to GitHub, let's jump back into our web browser and have a look at that index.yaml file. So if I refresh my page here, click on the index.yaml, and then click on the Raw button and grab that URL. This is the URL that we'll use to add our GitHub repository as a Helm repository. So, back in Visual Studio Code, we run the helm repo add, give our repository a name, dbafromthecold, and then take that URL, removing the index.yaml from the end. And there we have our repository added as a Helm repository locally. Now, what that did in the background was pull down a load of information about our repository locally. So let's have a look at the repositories.yaml file and see if we have a record for our new repository. Open it up, and there we go at the end there, I have a record for my new repository, dbafromthecold, with the raw URL that I pulled down from GitHub. Let's also have a look at the cached index.yaml file for that repository. This is the default location that I grabbed from helm help in the last demo, drop it into File Explorer, and there I can see dbafromthecold‑index.yaml. Opening that up, and there we go, there is the record for our chart. Now that we've added our repository, let's search it with helm search repo dbafromthecold/ourchart. And there we go, there is a record of our chart. We can also have a look at our chart in the Helm section of the Kubernetes extension for Visual Studio Code. Refreshing, there's our new repo, opening it up, and there is ourchart. Okay, final thing to do to test is deploy our chart from our repository. So helm install, release name, we're going to call it ourchart again, repository name, and then ourchart name. We can see this is deployed, and then we can finally confirm that with helm list. All looks good. We've successfully deployed our package chart from our remote Helm repository.